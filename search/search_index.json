{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"This server hosts proofs of concept that the Centre for Digital Scholarship (have) created in collaboration with researchers. We also provide resources to help you work with (digital) data. These resources will not cover every aspect of working with data, although we hope they can get you started. Working with (digital) data \u00b6 Learn about working with (digital) data . Current projects \u00b6 These are some example projects the CDS has worked on. Abnormal Hieratic Global Portal \u00b6 Community resource for studying Abnormal Hieratic manuscripts, developed in cooperation with the Faculty of Humanities. The project page has more information on the technical components. Lydgate \u00b6 Online edition of Leiden University Libraries' edition of the Lydgate manuscript, edited by students. Digital Manuscripts in the Classroom \u00b6 Leiden University Libraries have a great collection of manuscripts, but it is infeasible to use many of them for education, because they are rare and often fragile. This platform is being developed to allow online exploration of the manuscripts by theme. More details are available on the project page . Medieval Palaeography \u00b6 Mouse and Manuscript \u00b6 FromThePage transcription platform \u00b6 The CDS hosts an instance of the FromThePage platform . FromThePage is an open-source server application that allows researchers and institutions to let people help transcribe (and translate) works on a page-by-page basis. FromThePage is used in various projects. The source code for FromThePage is openly available at GitHub: benwbrum/fromthepage . Iran Turan \u00b6 The CDS set up Omeka Classic to support the Turks, texts and territory project . Soldaat in Indonesi\u00eb \u00b6 Online research environment for working with ego documents written by soldiers in Indonesia. IIIF portal \u00b6 The International Image Interoperability Framework (IIIF) portal for Leiden University aims to help users access the UBL digital collections via the various IIIF APIs and services based on the IIIF. This guide has been moved to /iiif-docs . Jan Wolkers puzzles \u00b6 The CDS used existing IIIF software to make a few of Jan Wolkers's works available as puzzles. Read more about this on the short project page . Mirador demonstrations \u00b6 Demonstrations of IIIF functionality using Mirador are hosted at IIIF demonstrations . UBL maps in Geoplaza \u00b6 Leiden University Libraries collaborated with the Vrije Universiteit Amsterdam to show 51 maps from our collections in the Geoplaza portal, but they are no longer online.","title":"Welcome to the Centre for Digital Scholarship's Lab"},{"location":"#working-with-digital-data","text":"Learn about working with (digital) data .","title":"Working with (digital) data"},{"location":"#current-projects","text":"These are some example projects the CDS has worked on.","title":"Current projects"},{"location":"#abnormal-hieratic-global-portal","text":"Community resource for studying Abnormal Hieratic manuscripts, developed in cooperation with the Faculty of Humanities. The project page has more information on the technical components.","title":"Abnormal Hieratic Global Portal"},{"location":"#lydgate","text":"Online edition of Leiden University Libraries' edition of the Lydgate manuscript, edited by students.","title":"Lydgate"},{"location":"#digital-manuscripts-in-the-classroom","text":"Leiden University Libraries have a great collection of manuscripts, but it is infeasible to use many of them for education, because they are rare and often fragile. This platform is being developed to allow online exploration of the manuscripts by theme. More details are available on the project page .","title":"Digital Manuscripts in the Classroom"},{"location":"#medieval-palaeography","text":"","title":"Medieval Palaeography"},{"location":"#mouse-and-manuscript","text":"","title":"Mouse and Manuscript"},{"location":"#fromthepage-transcription-platform","text":"The CDS hosts an instance of the FromThePage platform . FromThePage is an open-source server application that allows researchers and institutions to let people help transcribe (and translate) works on a page-by-page basis. FromThePage is used in various projects. The source code for FromThePage is openly available at GitHub: benwbrum/fromthepage .","title":"FromThePage transcription platform"},{"location":"#iran-turan","text":"The CDS set up Omeka Classic to support the Turks, texts and territory project .","title":"Iran Turan"},{"location":"#soldaat-in-indonesie","text":"Online research environment for working with ego documents written by soldiers in Indonesia.","title":"Soldaat in Indonesi\u00eb"},{"location":"#iiif-portal","text":"The International Image Interoperability Framework (IIIF) portal for Leiden University aims to help users access the UBL digital collections via the various IIIF APIs and services based on the IIIF. This guide has been moved to /iiif-docs .","title":"IIIF portal"},{"location":"#jan-wolkers-puzzles","text":"The CDS used existing IIIF software to make a few of Jan Wolkers's works available as puzzles. Read more about this on the short project page .","title":"Jan Wolkers puzzles"},{"location":"#mirador-demonstrations","text":"Demonstrations of IIIF functionality using Mirador are hosted at IIIF demonstrations .","title":"Mirador demonstrations"},{"location":"#ubl-maps-in-geoplaza","text":"Leiden University Libraries collaborated with the Vrije Universiteit Amsterdam to show 51 maps from our collections in the Geoplaza portal, but they are no longer online.","title":"UBL maps in Geoplaza"},{"location":"purl/","text":"When you create a website for a project or dataset and you want to ensure that the pages are accessible after the project ends or when the website is moved to a different location, you can use persistent URLs . The Centre for Digital Scholarship now supports the management of persistent URLs for research projects. Read on for terms and conditions. What are persistent URLs? \u00b6 Persistent URLs (PURLs for short) are long-lived URLs. They are not necessarily permanent , but the people or organisation managing PURLs intend to keep the content at the PURLs available for a long time. When the project ends and the domain name and webspace is no longer payed for, but you still want to have your website online, perhaps you can store a static version on a more permanent university-offered server. By using the PURL service to link to pages before you move, your links should keep working after the website moves to the different domain. What is the Persistent URLs service? \u00b6 The PURL service is available for the Leiden University research community to help with setting up persistent URLs for a website. This service is based on https://w3id.org/ and is meant for fairly simple redirects. What conditions does my project need to meet? \u00b6 The main consideration for the PURL service to work with your website is that the URLs have a simple structure. We cannot host your website, let alone re-engineer it for this to hold. Please get in touch with Ben Companjen to discuss your options.","title":"Persistent URLs"},{"location":"purl/#what-are-persistent-urls","text":"Persistent URLs (PURLs for short) are long-lived URLs. They are not necessarily permanent , but the people or organisation managing PURLs intend to keep the content at the PURLs available for a long time. When the project ends and the domain name and webspace is no longer payed for, but you still want to have your website online, perhaps you can store a static version on a more permanent university-offered server. By using the PURL service to link to pages before you move, your links should keep working after the website moves to the different domain.","title":"What are persistent URLs?"},{"location":"purl/#what-is-the-persistent-urls-service","text":"The PURL service is available for the Leiden University research community to help with setting up persistent URLs for a website. This service is based on https://w3id.org/ and is meant for fairly simple redirects.","title":"What is the Persistent URLs service?"},{"location":"purl/#what-conditions-does-my-project-need-to-meet","text":"The main consideration for the PURL service to work with your website is that the URLs have a simple structure. We cannot host your website, let alone re-engineer it for this to hold. Please get in touch with Ben Companjen to discuss your options.","title":"What conditions does my project need to meet?"},{"location":"projects/abnormal-hieratic/","text":"Community resource for studying Abnormal Hieratic manuscripts, developed in cooperation with the Faculty of Humanities. Visit the Abnormal Hieratic Global Portal Components \u00b6 WordPress Plugin: OIDC Plugin: ORCID Plugin: AH types Theme: Modern Child theme: AH based on Modern Elasticsearch Support files search interface Mirador interface Indexer Simple Annotation Server IIIF Manifests for the papyri Project history \u00b6","title":"The Abnormal Hieratic Global Portal"},{"location":"projects/abnormal-hieratic/#components","text":"WordPress Plugin: OIDC Plugin: ORCID Plugin: AH types Theme: Modern Child theme: AH based on Modern Elasticsearch Support files search interface Mirador interface Indexer Simple Annotation Server IIIF Manifests for the papyri","title":"Components"},{"location":"projects/abnormal-hieratic/#project-history","text":"","title":"Project history"},{"location":"projects/digmanclass/","text":"Digital Manuscripts in the Classroom is an Open Educational Resource teaching students about manuscripts using digitised items from the special collections at Leiden University Libraries . The availability of these items via IIIF allows easy integration of a deep-zoom viewer in the website. The website is created using the Jekyll static site generator.","title":"Digital Manuscripts in the Classroom"},{"location":"projects/french-manuscripts/","text":"See Intercultural Dialogue and Multilingualism in Post-Conquest England: A Database of French Literary Manuscripts Produced Between 1100-1550 and French Literary Manuscripts in England, 1100-1500 .","title":"French Manuscripts"},{"location":"projects/iran-turan/","text":"","title":"Iran Turan"},{"location":"projects/lydgate/","text":"","title":"Lydgate"},{"location":"projects/mouse/","text":"Mouse and Manuscript is a platform for hosting lessons on manuscripts from the Muslim and Coptic world. It has been developed in collaboration with Dorrit van Dalen, ECOLe and Strategic Communication and Marketing.","title":"Mouse and Manuscript"},{"location":"projects/nk-posters/","text":"The CDS helped convert the detailed descriptions of propaganda posters from North Korea to metadata that could be ingested into the Digital Collections repository . This is an excellent example of the support we offer for making your research data more FAIR and available in the long term. See VREs for more information.","title":"North-Korean poster collection"},{"location":"projects/paleo/","text":"","title":"Medieval Palaeography"},{"location":"projects/wolkers-puzzles/","text":"As part of the Waanzinnige Wolkers Week, the CDS and Special Collections department of Leiden University Libraries selected six images of Jan Wolkers's works and himself and created an online puzzle .","title":"Jan Wolkers puzzles"},{"location":"vre/","text":"What is a Virtual Research Environment (VRE)? \u00b6 See the Libraries' website on VREs to learn more about VREs and what Leiden University Libraries can do for you. Types of VREs \u00b6 Below are a few VRE platforms, although many more are available. VRE systems are usually tailored to tasks for specific research, although the generic ones below can be customised for many fields. SharePoint \u00b6 Library-managed VREs are based on Microsoft SharePoint. They allow collaborating on (office) documents, sharing files, and storing information in (a collection of interlinked) lists, among other features. The lists functionality is like a database and can be accessed from Microsoft Access and Microsoft Excel. GitLab \u00b6 GitLab is an online version control system based on git . The University hosts a GitLab service that you can use after logging in with your ULCN credentials: https://gitlab.services.universiteitleiden.nl/ . Git is most often used for versioning and sharing software source code, but it works with all text-based files and binary files too (although for large binary files you should look into git-lfs ). It requires a specific way of thinking about versioning to unleash all of git's functionality, but GitLab allows you to perform many operations through its web interface as well. Omeka S \u00b6 Omeka S is an open-source content management system for images and other content. It supports IIIF sources and exports data about items as RDF. The CDS is currently testing Omeka S. Nodegoat \u00b6 Nodegoat is an open-source online database system. The CDS does not currently use or support Nodegoat, but it is on our radar. The hosted service provided by the creators is free for individual researchers. Other VRE systems \u00b6 Digital Mappa and Recogito allow flexible annotation of documents and images that are available via IIIF. Wikibase is the underlying system that powers Wikidata , but it can also be used without any link to any Wikimedia projects. Wikibase allows collaborative data management in terms of (qualified) statements about things, supported by references. Exporting data from a SharePoint VRE for archiving or publication \u00b6 When a project ends, you usually stop using the virtual research environment for working on the project data. That doesn't mean you don't need the data anymore \u2013 that would be silly and probably not what you put in your data management plan! Your VRE will not be deleted without asking you first \u2013 and it is fine to keep it around indefinitely. However, you may find that the VRE is not the best way to make your data available to the wider world. You may therefore want to export the data to a different platform for preservation and more ease of use. The Centre for Digital Scholarship can help you export and convert the data so that it is easier to archive in a Trustworthy Digital Repository or use in offline analyses. Read more about migrating data from VREs . For example, the CDS helped with North-Korean posters .","title":"Virtual Research Environments"},{"location":"vre/#what-is-a-virtual-research-environment-vre","text":"See the Libraries' website on VREs to learn more about VREs and what Leiden University Libraries can do for you.","title":"What is a Virtual Research Environment (VRE)?"},{"location":"vre/#types-of-vres","text":"Below are a few VRE platforms, although many more are available. VRE systems are usually tailored to tasks for specific research, although the generic ones below can be customised for many fields.","title":"Types of VREs"},{"location":"vre/#sharepoint","text":"Library-managed VREs are based on Microsoft SharePoint. They allow collaborating on (office) documents, sharing files, and storing information in (a collection of interlinked) lists, among other features. The lists functionality is like a database and can be accessed from Microsoft Access and Microsoft Excel.","title":"SharePoint"},{"location":"vre/#gitlab","text":"GitLab is an online version control system based on git . The University hosts a GitLab service that you can use after logging in with your ULCN credentials: https://gitlab.services.universiteitleiden.nl/ . Git is most often used for versioning and sharing software source code, but it works with all text-based files and binary files too (although for large binary files you should look into git-lfs ). It requires a specific way of thinking about versioning to unleash all of git's functionality, but GitLab allows you to perform many operations through its web interface as well.","title":"GitLab"},{"location":"vre/#omeka-s","text":"Omeka S is an open-source content management system for images and other content. It supports IIIF sources and exports data about items as RDF. The CDS is currently testing Omeka S.","title":"Omeka S"},{"location":"vre/#nodegoat","text":"Nodegoat is an open-source online database system. The CDS does not currently use or support Nodegoat, but it is on our radar. The hosted service provided by the creators is free for individual researchers.","title":"Nodegoat"},{"location":"vre/#other-vre-systems","text":"Digital Mappa and Recogito allow flexible annotation of documents and images that are available via IIIF. Wikibase is the underlying system that powers Wikidata , but it can also be used without any link to any Wikimedia projects. Wikibase allows collaborative data management in terms of (qualified) statements about things, supported by references.","title":"Other VRE systems"},{"location":"vre/#exporting-data-from-a-sharepoint-vre-for-archiving-or-publication","text":"When a project ends, you usually stop using the virtual research environment for working on the project data. That doesn't mean you don't need the data anymore \u2013 that would be silly and probably not what you put in your data management plan! Your VRE will not be deleted without asking you first \u2013 and it is fine to keep it around indefinitely. However, you may find that the VRE is not the best way to make your data available to the wider world. You may therefore want to export the data to a different platform for preservation and more ease of use. The Centre for Digital Scholarship can help you export and convert the data so that it is easier to archive in a Trustworthy Digital Repository or use in offline analyses. Read more about migrating data from VREs . For example, the CDS helped with North-Korean posters .","title":"Exporting data from a SharePoint VRE for archiving or publication"},{"location":"vre/migration/","text":"This page describes the general process of moving data out of SharePoint and into a data model and data format that can be used in different contexts. In general, these converted data can be readily stored in a data archive. If you have a SharePoint VRE and would like to export your data, please contact the Centre for Digital Scholarship for information. Data modelling \u00b6 Unless you only used the VRE for sharing files that are read and edited outside the VRE, you probably have information that is managed directly in SharePoint. Such data may be stored in lists. The data model explains what the information is about. Some projects already started with a highly structured data model, other projects need more help to reshape their data into models that are more interoperable with existing datasets. In many cases, we will meet several times to discuss what your data describe and how data points are interrelated. Find models to map to \u00b6 For your data to be understandable to other researchers (or anyone else, really), it helps to \"speak the same language\", i.e. use common data models. Many people have already created data models to describe for example books, people, architecture and art, genes, et cetera. However, not everyone describes every item in the same way, so you may need to extend or adapt an existing data model. There are too many possible models to list here, so we only link to some databases that provide overviews of existing models: Linked Open Vocabularies (LOV) indexes ontologies and RDF Schemas FAIRsharing collects standards, databases and policies Iteratively create mapping(s) and test their correctness \u00b6 Use SharePoint's legacy XML export, REST API with Atom XML or download options in the web interface to get the data. Transform the data to the target model using, for example, XSLT or RML . Do not try to create a complete mapping in one go, but start simple and improve one step at a time. Perform the migration \u00b6 When you are happy with the results of your mapping and transformation testing, do it once more for all data and add metadata about the dataset, including its provenance. This is the data that you will publish, archive or maybe continue working on using other tools. Archive the data \u00b6 There are many services for archiving datasets, usually known as data archives. See the Research Data Services catalogue for information on data archives that we know of (though this catalogue is incomplete and may be out of date).","title":"Migrating or exporting data from a VRE"},{"location":"vre/migration/#data-modelling","text":"Unless you only used the VRE for sharing files that are read and edited outside the VRE, you probably have information that is managed directly in SharePoint. Such data may be stored in lists. The data model explains what the information is about. Some projects already started with a highly structured data model, other projects need more help to reshape their data into models that are more interoperable with existing datasets. In many cases, we will meet several times to discuss what your data describe and how data points are interrelated.","title":"Data modelling"},{"location":"vre/migration/#find-models-to-map-to","text":"For your data to be understandable to other researchers (or anyone else, really), it helps to \"speak the same language\", i.e. use common data models. Many people have already created data models to describe for example books, people, architecture and art, genes, et cetera. However, not everyone describes every item in the same way, so you may need to extend or adapt an existing data model. There are too many possible models to list here, so we only link to some databases that provide overviews of existing models: Linked Open Vocabularies (LOV) indexes ontologies and RDF Schemas FAIRsharing collects standards, databases and policies","title":"Find models to map to"},{"location":"vre/migration/#iteratively-create-mappings-and-test-their-correctness","text":"Use SharePoint's legacy XML export, REST API with Atom XML or download options in the web interface to get the data. Transform the data to the target model using, for example, XSLT or RML . Do not try to create a complete mapping in one go, but start simple and improve one step at a time.","title":"Iteratively create mapping(s) and test their correctness"},{"location":"vre/migration/#perform-the-migration","text":"When you are happy with the results of your mapping and transformation testing, do it once more for all data and add metadata about the dataset, including its provenance. This is the data that you will publish, archive or maybe continue working on using other tools.","title":"Perform the migration"},{"location":"vre/migration/#archive-the-data","text":"There are many services for archiving datasets, usually known as data archives. See the Research Data Services catalogue for information on data archives that we know of (though this catalogue is incomplete and may be out of date).","title":"Archive the data"},{"location":"working-with-data/","text":"Digital scholarship nearly always involves working with digital data. Because working with is rather abstract, we often view data as artifacts that you can create , process , analyse , preserve , share and re-use . These activities can be viewed as a cycle, since re-using data can lead to creating new data. This cycle is sourced from the UK Data Service . There are various other cycles that are used to guide data management, discussed by Alex Ball in Review of Data Management Lifecycle Models (2012) . Creating data \u00b6 Collaborate on data with a VRE Virtual Research Environments allow you to work together on a (data) project. See VREs for more information. \"Collaborative data maintenance\" \u00b6 The Collaborative Data Patterns website contains great explanations of things to think of when you work together on a dataset. Processing data \u00b6 Analysing data \u00b6 Preserving data \u00b6 Giving access to data \u00b6 The CDS promotes making your data [FAIR], especially when sharing it. Publishing your data has more on making your data available in FAIR ways. Using Persistent URLs See Persistent URLs for information about persistent URLs for your data. Re-using data \u00b6 Enriching resources is an excellent example of re-using data. To get data, you may get datasets from data archives, from APIs or perhaps even by scraping them from webpages.","title":"Working with (digital) data"},{"location":"working-with-data/#creating-data","text":"Collaborate on data with a VRE Virtual Research Environments allow you to work together on a (data) project. See VREs for more information.","title":"Creating data"},{"location":"working-with-data/#collaborative-data-maintenance","text":"The Collaborative Data Patterns website contains great explanations of things to think of when you work together on a dataset.","title":"\"Collaborative data maintenance\""},{"location":"working-with-data/#processing-data","text":"","title":"Processing data"},{"location":"working-with-data/#analysing-data","text":"","title":"Analysing data"},{"location":"working-with-data/#preserving-data","text":"","title":"Preserving data"},{"location":"working-with-data/#giving-access-to-data","text":"The CDS promotes making your data [FAIR], especially when sharing it. Publishing your data has more on making your data available in FAIR ways. Using Persistent URLs See Persistent URLs for information about persistent URLs for your data.","title":"Giving access to data"},{"location":"working-with-data/#re-using-data","text":"Enriching resources is an excellent example of re-using data. To get data, you may get datasets from data archives, from APIs or perhaps even by scraping them from webpages.","title":"Re-using data"},{"location":"working-with-data/analysing-data/","text":"","title":"Analysing data"},{"location":"working-with-data/analysing-data/twitter/","text":"Twitter is a well-known and widely used source for research. Academics and journalists use it to gauge what is on people's minds and how the general population think about certain topics. For business and ethical reasons, Twitter limits (free) access to the live stream of all tweets and to the full archive of all tweets published since Twitter's start. However, other ways of getting tweets are available. Get started \u00b6 For a beginner's tutorial to getting tweets and analysing them, please see: Brad Rittenhouse, Ximin Mi, and Courtney Allen, \"Beginner's Guide to Twitter Data,\" The Programming Historian 8 (2019), https://doi.org/10.46430/phen0083 . Ethics and Terms of use \u00b6 As a general note: please consider the ethics of using tweets, as well as Twitter's terms of use. Many Twitter users do not regard publishing tweets to include consenting to all forms of research. The University of Sheffield notes in Research Ethics Policy Note no. 14 that social media data is considered research on human subjects. For politicians there are probably other considerations to include. Also, the free Twitter APIs do not provide access to all tweets, so the data set will not be a complete view of the 'Twittersphere'. The blog post Twitter\u2019s Developer Policies for Researchers, Archivists, and Librarians discusses Twitter's August 2018 changes to their terms and conditions for research and archiving. Software \u00b6 In terms of software: the SOLO department ( solo@fsw.leidenuniv.nl ) at the Faculty of Social and Behavioural Sciences has a bulk license for ATLAS.ti, which is used for discourse analysis and includes functionality to get data from Twitter. Other tools include text mining software like Orange 3 with the text mining plugin or KNIME .","title":"Analysing Twitter data"},{"location":"working-with-data/analysing-data/twitter/#get-started","text":"For a beginner's tutorial to getting tweets and analysing them, please see: Brad Rittenhouse, Ximin Mi, and Courtney Allen, \"Beginner's Guide to Twitter Data,\" The Programming Historian 8 (2019), https://doi.org/10.46430/phen0083 .","title":"Get started"},{"location":"working-with-data/analysing-data/twitter/#ethics-and-terms-of-use","text":"As a general note: please consider the ethics of using tweets, as well as Twitter's terms of use. Many Twitter users do not regard publishing tweets to include consenting to all forms of research. The University of Sheffield notes in Research Ethics Policy Note no. 14 that social media data is considered research on human subjects. For politicians there are probably other considerations to include. Also, the free Twitter APIs do not provide access to all tweets, so the data set will not be a complete view of the 'Twittersphere'. The blog post Twitter\u2019s Developer Policies for Researchers, Archivists, and Librarians discusses Twitter's August 2018 changes to their terms and conditions for research and archiving.","title":"Ethics and Terms of use"},{"location":"working-with-data/analysing-data/twitter/#software","text":"In terms of software: the SOLO department ( solo@fsw.leidenuniv.nl ) at the Faculty of Social and Behavioural Sciences has a bulk license for ATLAS.ti, which is used for discourse analysis and includes functionality to get data from Twitter. Other tools include text mining software like Orange 3 with the text mining plugin or KNIME .","title":"Software"},{"location":"working-with-data/enriching-resources/","text":"Are you interested in 'doing something' with digital artefacts from (cultural) heritage institutions? Do you want to collect, describe, annotate or present them in a certain way, as part of your research or for any other purpose? Then this guide may be for you. This guide aims to help researchers plan and execute projects that include any or all of the above activities. It is (being) written by the Centre for Digital Scholarship, who help researchers at Leiden University use digital data, manage research data and publish in Open Access. We consider enriching objects to be both working with digital data and creating and managing research data . The guide covers: definitions of (digital) objects and enriching objects goals of enriching objects sources of objects to enrich what kinds of enrichments exist where to store your enrichments and how to share them This document can be used as a reference for (research) projects in which (digital) objects are collected, described, annotated and presented. If you intend to perform these activities, you are reusing and creating data. Especially when you data you want to use come from cultural heritage collections, we say you are enriching the objects. Doing this properly can save you and others lots of effort and it will definitely make your research better. It is not meant as a template for projects that you fill out like a form, but you should be able to use it as inspiration for writing your project proposal. For any questions, please get in touch with the Centre for Digital Scholarship . Definitions of terms \u00b6 What are digital objects? \u00b6 Digital objects are artefacts in our digital collections. They may be digital representations of 'analog' objects or born-digital materials. The digital objects that are subject to these policies are the ones that Libraries have taken custodianship over. What is 'enriching digital objects'? \u00b6 Enriching a digital object means putting the object in context(s) by adding information or linking to related information or objects to provide more value to the object's users. Enriching an object, depending on your goals, could include: providing a description of the object's contents so that it can be better indexed or understood providing a link to a similar object provide provenance analysis transcribe text in images Goals of enrichment \u00b6 As with any project, you should first understand the goals of the project in which you want to enrich objects. Think about: What research questions are you trying to answer? How is enriching objects helping you to answer your questions? Intuitively, you need to enrich objects because the objects themselves and existing descriptions do not give you the information that helps you answer your research questions. Example If you want to know how often a cat appears in photos in a specific collection, but the metadata describing the photographs do not mention whether a cat is present, you may want to collect this data. To help others with similar questions and to show off your work, you could enrich the photographs by adding cat or no cat as annotations. If you create these annotations in a standardised, digital way, a script can then easily tally the number of photographs with and without cats. Will you be working with a few example objects or are you trying to generalise by working with a large set of objects? Who else might be interested in the results of your enrichment activities? What other projects have inspired you to try this? Sources: objects to enrich \u00b6 What is your source material? Where will you get it? Who owns the rights to the source materials? Objects may be textual, visual, audible or of a different nature \u2013 or of a combination of 'natures'. The type(s) of your source materials will influence the way you work with them, starting with how you retrieve them. If the objects you want to collect and enrich are available online, published by trustworthy archives or libraries, accessible via persistent identifiers and stable and open protocols, there is no need to create copies on your own computer. Copying such objects may even make your research harder, as you have to pay for the extra storage, manage backups 1 , find a way to share 'your' copies with colleagues and make sure your enrichments can be linked to the originals. It is a different story when the originals are not digitised, only available within the holding institution, or don't have persistent identifiers. Maybe for security or privacy you can only work with them offline, with strict access controls for everything related to the objects \u2013 including enrichments. This will not be covered in this guide. In some cases it is okay to create digital representations of objects yourself and use those in the project. Note that you may need approval from the owner or holding institute. Also, you will also need to describe the representations, keep links to the originals through identifiers and arrange for storage. Creating representations of objects should be done in a very consistent manner, following best practices for the specific types of objects and the goals of the project. Models for objects and enrichments \u00b6 Depending on the type of objects you are using, different kinds of enrichments can be used. The way you refer to (fragments of) objects varies as well. What are the parts to each of your objects? Files, metadata files, database rows? What do you want to do with your objects? Add descriptions of the whole object, or parts of the object? Do you want to link to other objects in the same collection, or link to external objects or concepts? What are the parts to each of your enrichments? A collection name, general description, tags, contextual information? Do you put them in a Word document, HTML files, a spreadsheet, a database, an annotation service? System components and procedures \u00b6 To perform the actual enrichment, you will need a method \u2013 tools (e.g. software) that help you create and store enrichments and procedures for working with the tools. In the past, perhaps you would take structured notes on index cards and share (copies of) the cards with researchers that you know. Nowadays, you may want to select parts of an image and fill a few fields in a form right next to the image and allow non-expert citizen scientists to help you (with automatic validation of their input). Your goals, sources and models all influence how the system should be configured and what procedures you need to have in place. Keep in mind that systems and system components need maintenance and usually cost money. This may mean that systems or components that you use during the project are not necessarily available (let alone maintained) after the project, unless you can afford keeping them available using other funds and/or organisational infrastructure. You should always ensure that any enrichments you create in your project can be used outside the system(s) you use to create them. Procedures \u00b6 collecting sources not available online basic description of sources creating enrichments grouping enrichments in versioned datasets updating enrichments authorising users (researchers, non-experts) training humans training machines discussing enrichments validating enrichments presenting enrichments System components \u00b6 Content Management System authentication and authorisation of users publication of sources with basic descriptions publication of tutorials annotation tool(s) machine learning tool(s) data conversion tools data import tools data management / archiving system Storage and publication \u00b6 As mentioned above, you should ensure your data is stored safely to prevent loss and unauthorised access and changes. See Data protection for some pointers. Ideally your enrichments are available via standard interfaces and protocols as soon as possible after their creation (and possibly validation). Even better is when they are available for the long term with persistent identifiers that resolve to the latest location when the data of your enrichment are relocated to other computers. You should archive your enrichments in a research data archive at least once, at the end of the project, or when the enrichments are finished. This ensures that nothing is lost, even if the system is shut down at the end of the project. It also allows you to cite the data as a dataset in your own publications. You should already have a way of managing backups of everything important on your computer. Ask your IT department for help with this. \u21a9","title":"Generic guidance for enrichment projects"},{"location":"working-with-data/enriching-resources/#definitions-of-terms","text":"","title":"Definitions of terms"},{"location":"working-with-data/enriching-resources/#what-are-digital-objects","text":"Digital objects are artefacts in our digital collections. They may be digital representations of 'analog' objects or born-digital materials. The digital objects that are subject to these policies are the ones that Libraries have taken custodianship over.","title":"What are digital objects?"},{"location":"working-with-data/enriching-resources/#what-is-enriching-digital-objects","text":"Enriching a digital object means putting the object in context(s) by adding information or linking to related information or objects to provide more value to the object's users. Enriching an object, depending on your goals, could include: providing a description of the object's contents so that it can be better indexed or understood providing a link to a similar object provide provenance analysis transcribe text in images","title":"What is 'enriching digital objects'?"},{"location":"working-with-data/enriching-resources/#goals-of-enrichment","text":"As with any project, you should first understand the goals of the project in which you want to enrich objects. Think about: What research questions are you trying to answer? How is enriching objects helping you to answer your questions? Intuitively, you need to enrich objects because the objects themselves and existing descriptions do not give you the information that helps you answer your research questions. Example If you want to know how often a cat appears in photos in a specific collection, but the metadata describing the photographs do not mention whether a cat is present, you may want to collect this data. To help others with similar questions and to show off your work, you could enrich the photographs by adding cat or no cat as annotations. If you create these annotations in a standardised, digital way, a script can then easily tally the number of photographs with and without cats. Will you be working with a few example objects or are you trying to generalise by working with a large set of objects? Who else might be interested in the results of your enrichment activities? What other projects have inspired you to try this?","title":"Goals of enrichment"},{"location":"working-with-data/enriching-resources/#sources-objects-to-enrich","text":"What is your source material? Where will you get it? Who owns the rights to the source materials? Objects may be textual, visual, audible or of a different nature \u2013 or of a combination of 'natures'. The type(s) of your source materials will influence the way you work with them, starting with how you retrieve them. If the objects you want to collect and enrich are available online, published by trustworthy archives or libraries, accessible via persistent identifiers and stable and open protocols, there is no need to create copies on your own computer. Copying such objects may even make your research harder, as you have to pay for the extra storage, manage backups 1 , find a way to share 'your' copies with colleagues and make sure your enrichments can be linked to the originals. It is a different story when the originals are not digitised, only available within the holding institution, or don't have persistent identifiers. Maybe for security or privacy you can only work with them offline, with strict access controls for everything related to the objects \u2013 including enrichments. This will not be covered in this guide. In some cases it is okay to create digital representations of objects yourself and use those in the project. Note that you may need approval from the owner or holding institute. Also, you will also need to describe the representations, keep links to the originals through identifiers and arrange for storage. Creating representations of objects should be done in a very consistent manner, following best practices for the specific types of objects and the goals of the project.","title":"Sources: objects to enrich"},{"location":"working-with-data/enriching-resources/#models-for-objects-and-enrichments","text":"Depending on the type of objects you are using, different kinds of enrichments can be used. The way you refer to (fragments of) objects varies as well. What are the parts to each of your objects? Files, metadata files, database rows? What do you want to do with your objects? Add descriptions of the whole object, or parts of the object? Do you want to link to other objects in the same collection, or link to external objects or concepts? What are the parts to each of your enrichments? A collection name, general description, tags, contextual information? Do you put them in a Word document, HTML files, a spreadsheet, a database, an annotation service?","title":"Models for objects and enrichments"},{"location":"working-with-data/enriching-resources/#system-components-and-procedures","text":"To perform the actual enrichment, you will need a method \u2013 tools (e.g. software) that help you create and store enrichments and procedures for working with the tools. In the past, perhaps you would take structured notes on index cards and share (copies of) the cards with researchers that you know. Nowadays, you may want to select parts of an image and fill a few fields in a form right next to the image and allow non-expert citizen scientists to help you (with automatic validation of their input). Your goals, sources and models all influence how the system should be configured and what procedures you need to have in place. Keep in mind that systems and system components need maintenance and usually cost money. This may mean that systems or components that you use during the project are not necessarily available (let alone maintained) after the project, unless you can afford keeping them available using other funds and/or organisational infrastructure. You should always ensure that any enrichments you create in your project can be used outside the system(s) you use to create them.","title":"System components and procedures"},{"location":"working-with-data/enriching-resources/#procedures","text":"collecting sources not available online basic description of sources creating enrichments grouping enrichments in versioned datasets updating enrichments authorising users (researchers, non-experts) training humans training machines discussing enrichments validating enrichments presenting enrichments","title":"Procedures"},{"location":"working-with-data/enriching-resources/#system-components","text":"Content Management System authentication and authorisation of users publication of sources with basic descriptions publication of tutorials annotation tool(s) machine learning tool(s) data conversion tools data import tools data management / archiving system","title":"System components"},{"location":"working-with-data/enriching-resources/#storage-and-publication","text":"As mentioned above, you should ensure your data is stored safely to prevent loss and unauthorised access and changes. See Data protection for some pointers. Ideally your enrichments are available via standard interfaces and protocols as soon as possible after their creation (and possibly validation). Even better is when they are available for the long term with persistent identifiers that resolve to the latest location when the data of your enrichment are relocated to other computers. You should archive your enrichments in a research data archive at least once, at the end of the project, or when the enrichments are finished. This ensures that nothing is lost, even if the system is shut down at the end of the project. It also allows you to cite the data as a dataset in your own publications. You should already have a way of managing backups of everything important on your computer. Ask your IT department for help with this. \u21a9","title":"Storage and publication"},{"location":"working-with-data/enriching-resources/cookbook/","text":"This cookbook contains recipes for enrichment of digital objects. It is never finished and non-normative, and will have lots of links to examples elsewhere. However, it is the intention of the Centre for Digital Scholarship to provide good examples and not to create a comprehensive list of every project ever undertaken. Example enrichments \u00b6 Identify people in images \u00b6 Warning Mind the rules for working with data about people. Here are two ways of identifying people in images. Assuming that the abstract representation of the image is more stable and versatile than individual images, annotating the canvas is preferred. Annotate (part of) the Canvas (preferred) \u00b6 Create a [Canvas][] for the image, if it doesn't exist yet. Annotate the part (i.e. fragment) of the Canvas with a Web Annotation with the identifying motivation and the URI of the person as the body. Annotate (part of) the image directly \u00b6 Annotate the part (i.e. fragment) of the image with a Web Annotation with the identifying motivation and the URI of the person as the body. Classify objects in images \u00b6 When you cannot or do not want to identify specific objects, but do want to say what kind of object they are, you can link an object class to (part of) an image. Warning Understand the ethics of classifying real-world objects, including (especially) people or peoples and objects involved in disputes. Annotate the part (i.e. fragment) of the Canvas or image with a Web Annotation with the classifying motivation and the URI of the object as the body URI. Link an image to its original \u00b6 If you believe an image is derived from another image, you can link them in the following way: (TODO) Example workflows \u00b6 Record tags for items in a spreadsheet \u00b6 When you want to assign a single tag to each item, put the identifier for the item the first column and the tag in the second. When you want to assign one or more tags to each item, you can either: add a row for each combination of item and tag concatenate the tags in the second column, separated by a comma, semicolon or other character that is never part of the tag Note Spreadsheets allow data entry in very flexible ways. However, for reusability you should stick to keeping your data in a rectangular table.","title":"Enrichments cookbook"},{"location":"working-with-data/enriching-resources/cookbook/#example-enrichments","text":"","title":"Example enrichments"},{"location":"working-with-data/enriching-resources/cookbook/#identify-people-in-images","text":"Warning Mind the rules for working with data about people. Here are two ways of identifying people in images. Assuming that the abstract representation of the image is more stable and versatile than individual images, annotating the canvas is preferred.","title":"Identify people in images"},{"location":"working-with-data/enriching-resources/cookbook/#annotate-part-of-the-canvas-preferred","text":"Create a [Canvas][] for the image, if it doesn't exist yet. Annotate the part (i.e. fragment) of the Canvas with a Web Annotation with the identifying motivation and the URI of the person as the body.","title":"Annotate (part of) the Canvas (preferred)"},{"location":"working-with-data/enriching-resources/cookbook/#annotate-part-of-the-image-directly","text":"Annotate the part (i.e. fragment) of the image with a Web Annotation with the identifying motivation and the URI of the person as the body.","title":"Annotate (part of) the image directly"},{"location":"working-with-data/enriching-resources/cookbook/#classify-objects-in-images","text":"When you cannot or do not want to identify specific objects, but do want to say what kind of object they are, you can link an object class to (part of) an image. Warning Understand the ethics of classifying real-world objects, including (especially) people or peoples and objects involved in disputes. Annotate the part (i.e. fragment) of the Canvas or image with a Web Annotation with the classifying motivation and the URI of the object as the body URI.","title":"Classify objects in images"},{"location":"working-with-data/enriching-resources/cookbook/#link-an-image-to-its-original","text":"If you believe an image is derived from another image, you can link them in the following way: (TODO)","title":"Link an image to its original"},{"location":"working-with-data/enriching-resources/cookbook/#example-workflows","text":"","title":"Example workflows"},{"location":"working-with-data/enriching-resources/cookbook/#record-tags-for-items-in-a-spreadsheet","text":"When you want to assign a single tag to each item, put the identifier for the item the first column and the tag in the second. When you want to assign one or more tags to each item, you can either: add a row for each combination of item and tag concatenate the tags in the second column, separated by a comma, semicolon or other character that is never part of the tag Note Spreadsheets allow data entry in very flexible ways. However, for reusability you should stick to keeping your data in a rectangular table.","title":"Record tags for items in a spreadsheet"},{"location":"working-with-data/enriching-resources/enrichment/","text":"Digital manuscripts are manuscripts that have been digitised. Images of the manuscript, combined with some metadata describing the manuscript and technical information about its structure, make the digital manuscript useable for viewing and reading. Creating a digital manuscript object \u00b6 We use the IIIF APIs for providing access to the images and their metadata. This means the images are made available through an IIIF Image server and a Manifest is created (semi-automatically) according to the specifications of the Presentation API. Adding transcriptions and translations \u00b6 We use the open-source application FromThePage to transcribe and translate digital manuscripts. To start a transcription project, you should import the manuscript by loading the IIIF Manifest file into FromThePage. You need to be authorised before you can do this. Adding notes to manuscripts and discussing manuscripts \u00b6 FromThePage can also be used to add notes to certain pages, for example to comment on a translation or to draw attention to a region of the page. For discussing the whole manuscript (when it consists of multiple pages), you can write a blogpost on this WordPress site and let other users comment, or start a forum topic. Viewing digital manuscripts \u00b6 Digital manuscripts can be viewed in detail using a IIIF viewer like Mirador or Tify. The viewers can be embedded within WordPress posts or be external to WordPress. Note that not all viewers can show transcriptions or translations with the images.","title":"Enriching digital manuscripts"},{"location":"working-with-data/enriching-resources/enrichment/#creating-a-digital-manuscript-object","text":"We use the IIIF APIs for providing access to the images and their metadata. This means the images are made available through an IIIF Image server and a Manifest is created (semi-automatically) according to the specifications of the Presentation API.","title":"Creating a digital manuscript object"},{"location":"working-with-data/enriching-resources/enrichment/#adding-transcriptions-and-translations","text":"We use the open-source application FromThePage to transcribe and translate digital manuscripts. To start a transcription project, you should import the manuscript by loading the IIIF Manifest file into FromThePage. You need to be authorised before you can do this.","title":"Adding transcriptions and translations"},{"location":"working-with-data/enriching-resources/enrichment/#adding-notes-to-manuscripts-and-discussing-manuscripts","text":"FromThePage can also be used to add notes to certain pages, for example to comment on a translation or to draw attention to a region of the page. For discussing the whole manuscript (when it consists of multiple pages), you can write a blogpost on this WordPress site and let other users comment, or start a forum topic.","title":"Adding notes to manuscripts and discussing manuscripts"},{"location":"working-with-data/enriching-resources/enrichment/#viewing-digital-manuscripts","text":"Digital manuscripts can be viewed in detail using a IIIF viewer like Mirador or Tify. The viewers can be embedded within WordPress posts or be external to WordPress. Note that not all viewers can show transcriptions or translations with the images.","title":"Viewing digital manuscripts"},{"location":"working-with-data/enriching-resources/faq/","text":"General questions \u00b6 What are digital objects? \u00b6 What is enrichment? \u00b6 Proposing an enrichment project \u00b6 Do I need to create a project? \u00b6 How do I start an enrichment project? \u00b6 What should I think about in my proposal? \u00b6 Permissions \u00b6 How can I know if I can use images for my research? \u00b6 How do I ask for permission to use images? \u00b6","title":"Frequently Asked Questions about enrichment"},{"location":"working-with-data/enriching-resources/faq/#general-questions","text":"","title":"General questions"},{"location":"working-with-data/enriching-resources/faq/#what-are-digital-objects","text":"","title":"What are digital objects?"},{"location":"working-with-data/enriching-resources/faq/#what-is-enrichment","text":"","title":"What is enrichment?"},{"location":"working-with-data/enriching-resources/faq/#proposing-an-enrichment-project","text":"","title":"Proposing an enrichment project"},{"location":"working-with-data/enriching-resources/faq/#do-i-need-to-create-a-project","text":"","title":"Do I need to create a project?"},{"location":"working-with-data/enriching-resources/faq/#how-do-i-start-an-enrichment-project","text":"","title":"How do I start an enrichment project?"},{"location":"working-with-data/enriching-resources/faq/#what-should-i-think-about-in-my-proposal","text":"","title":"What should I think about in my proposal?"},{"location":"working-with-data/enriching-resources/faq/#permissions","text":"","title":"Permissions"},{"location":"working-with-data/enriching-resources/faq/#how-can-i-know-if-i-can-use-images-for-my-research","text":"","title":"How can I know if I can use images for my research?"},{"location":"working-with-data/enriching-resources/faq/#how-do-i-ask-for-permission-to-use-images","text":"","title":"How do I ask for permission to use images?"},{"location":"working-with-data/enriching-resources/policy-av/","text":"Introduction \u00b6 This document should guide people who want to enrich audio(visual) materials such as videos, films, podcasts with descriptive metadata, details, context, or what have you. The policies in this document are (somewhat) concrete recommendations for implementing the guiding principles in the Enrichment Policy Framework . Both the framework and the policies in this document are based on the Leiden University research data management policy framework . Policies \u00b6 Use IIIF and the Web Annotation Framework if possible \u00b6 The International Image Interoperability Framework (IIIF) is a community-based set of standards for publishing, presenting, describing and annotating images on the Web \u2013 and AV resources as well, as of Presentation API 3.0 . IIIF relies heavily on the Web Annotation Framework , a W3C standard for annotating Web resources. Create abstract resources to annotate \u00b6 Use IIIF Canvases for pages/posters and annotate those instead of AV resources themselves. This is standard practice for IIIF-based resources. Don't copy if not necessary, always annotate the original \u00b6 If you want to enrich AV resources provided online by trustworthy institutions you don't need to copy the resources. It is okay to keep a backup copy, but connect enrichments to the originals to make them as useful as possible. Add provenance to annotations \u00b6 The Web Annotation Framework includes ways to attribute the creator(s) of each annotation, the time the annotation was created/generated, and the time(s) the annotation was modified. The tool(s) you use to annotate should help you keep track of your own work so that you can be credited for it, and held accountable. Keep provenance and licenses of source resources \u00b6 Explain how the set of resources you selected for enrichment was created. This helps people assess how complete your set is and how representative it is among all similar resources. If you have copies of resources, keep the licence conditions and creator information (and all other relevant provenance) close and preferably linked to the resources. You need to cite and deposit your data and this will help determine if and how resources can be shared. Store enrichments in a trustworthy data repository \u00b6 If using IIIF and e.g. (some annotation editor for AV resources) to create and save annotations, make sure the annotations are stored on a server that securely stores them and that creates backups. The server should store the provenance of each annotation too and if necessary, all versions of annotations. Identify, identify, identify \u00b6 Make sure everything has identifiers, preferably persistent identifiers (PIDs). You should use PIDs for AV resources you annotate, and the server that stores your annotations should create PIDs for each (version of an) annotation. This allows users to connect the right versions of annotations to the right versions of resources and recreate the context of the annotation at the time of its creation. Projects and Tools \u00b6 CLARIAH video annotation interoperability : discussion around Web Annotations for videos. Semantic Annotation Tool : front-end ( Waldorf.js and back-end ( Statler that work with HTML5, JavaScript and Web Annotations. ELAN : offline annotator that creates EAF files and various other annotation formats and connects to online knowledge bases for data categories (like CLARIN). VIAN : not generally available yet.","title":"Policies for enriching audio-visual materials"},{"location":"working-with-data/enriching-resources/policy-av/#introduction","text":"This document should guide people who want to enrich audio(visual) materials such as videos, films, podcasts with descriptive metadata, details, context, or what have you. The policies in this document are (somewhat) concrete recommendations for implementing the guiding principles in the Enrichment Policy Framework . Both the framework and the policies in this document are based on the Leiden University research data management policy framework .","title":"Introduction"},{"location":"working-with-data/enriching-resources/policy-av/#policies","text":"","title":"Policies"},{"location":"working-with-data/enriching-resources/policy-av/#use-iiif-and-the-web-annotation-framework-if-possible","text":"The International Image Interoperability Framework (IIIF) is a community-based set of standards for publishing, presenting, describing and annotating images on the Web \u2013 and AV resources as well, as of Presentation API 3.0 . IIIF relies heavily on the Web Annotation Framework , a W3C standard for annotating Web resources.","title":"Use IIIF and the Web Annotation Framework if possible"},{"location":"working-with-data/enriching-resources/policy-av/#create-abstract-resources-to-annotate","text":"Use IIIF Canvases for pages/posters and annotate those instead of AV resources themselves. This is standard practice for IIIF-based resources.","title":"Create abstract resources to annotate"},{"location":"working-with-data/enriching-resources/policy-av/#dont-copy-if-not-necessary-always-annotate-the-original","text":"If you want to enrich AV resources provided online by trustworthy institutions you don't need to copy the resources. It is okay to keep a backup copy, but connect enrichments to the originals to make them as useful as possible.","title":"Don't copy if not necessary, always annotate the original"},{"location":"working-with-data/enriching-resources/policy-av/#add-provenance-to-annotations","text":"The Web Annotation Framework includes ways to attribute the creator(s) of each annotation, the time the annotation was created/generated, and the time(s) the annotation was modified. The tool(s) you use to annotate should help you keep track of your own work so that you can be credited for it, and held accountable.","title":"Add provenance to annotations"},{"location":"working-with-data/enriching-resources/policy-av/#keep-provenance-and-licenses-of-source-resources","text":"Explain how the set of resources you selected for enrichment was created. This helps people assess how complete your set is and how representative it is among all similar resources. If you have copies of resources, keep the licence conditions and creator information (and all other relevant provenance) close and preferably linked to the resources. You need to cite and deposit your data and this will help determine if and how resources can be shared.","title":"Keep provenance and licenses of source resources"},{"location":"working-with-data/enriching-resources/policy-av/#store-enrichments-in-a-trustworthy-data-repository","text":"If using IIIF and e.g. (some annotation editor for AV resources) to create and save annotations, make sure the annotations are stored on a server that securely stores them and that creates backups. The server should store the provenance of each annotation too and if necessary, all versions of annotations.","title":"Store enrichments in a trustworthy data repository"},{"location":"working-with-data/enriching-resources/policy-av/#identify-identify-identify","text":"Make sure everything has identifiers, preferably persistent identifiers (PIDs). You should use PIDs for AV resources you annotate, and the server that stores your annotations should create PIDs for each (version of an) annotation. This allows users to connect the right versions of annotations to the right versions of resources and recreate the context of the annotation at the time of its creation.","title":"Identify, identify, identify"},{"location":"working-with-data/enriching-resources/policy-av/#projects-and-tools","text":"CLARIAH video annotation interoperability : discussion around Web Annotations for videos. Semantic Annotation Tool : front-end ( Waldorf.js and back-end ( Statler that work with HTML5, JavaScript and Web Annotations. ELAN : offline annotator that creates EAF files and various other annotation formats and connects to online knowledge bases for data categories (like CLARIN). VIAN : not generally available yet.","title":"Projects and Tools"},{"location":"working-with-data/enriching-resources/policy-framework/","text":"See the definitions of objects and enriching before reading on. Principles \u00b6 annotations are research data annotations enrich objects by adding or linking to information privacy of annotators ethical processing of annotation objects secure access to annotations preservation of annotations Laws and regulations \u00b6 GDPR: see Data protection on the library website for some pointers Copyright Policies \u00b6 Digitaal Erfgoed Referentiearchitectuur (DERA) defines four operational goals to implement its strategic goal, the third of which is 'Users can add new or external information when necessary.' This reference architecture is aimed at cultural heritage institutions, but this specific goal is clearly connected to our aim \u2013 to allow people to enrich digital objects. Links between objects and enrichments \u00b6 Define object bounds and types of enrichments. Objects may consist of various components, like high-resolution master image(s), thumbnail(s) and transcriptions of the text in the object. Model enrichments as annotations directly or use an annotation to make discovering more complex external descriptions of the resource easier. The latter use of annotations may be useful when an enrichment is more than a single connection between two objects. Annotations are research data \u00b6 All policies for research data also apply to annotations, and hence to enrichments as well. Enrichments should (thus) be FAIR. Use standards for annotations, like the Web Annotation Model . Considerations \u00b6 Data formats for annotations \u00b6 RDF CSV + CSV metadata JSON-LD Turtle RDFa Nanopublications other data formats Hypothes.is JSON brat stand-off format TEI VGG Image Annotator format (JSON or CSV) Bodies of annotations \u00b6 Annotations can have one or more bodies, or none (for specific motivations). If there are multiple bodies, they are usually related, but how they are related may vary. external, can be anything full resources fragments of resources embedded TextualBody HTML fragment plain text Example: TEI file as external body \u00b6 When you transcribe text from manuscripts, you may want to use the TEI guidelines and markup. You can refer to (fragments of) external TEI files as the body of annotations. Example: HTML file as external body \u00b6 Many documents on the Web are available in HTML format. You can refer to (fragments of) HTML files as the body of annotations. Motivation and purpose of annotations \u00b6 In the Web Annotation Model, motivation and purpose are used to present a reason for the annotation, thereby also explaining the nature of the relationship between the target and the body of the annotation. Note The motivations and purposes defined by the Web Annotation Model are useful, but deliberately generic. They can be specialised, though any terms created for special purposes should get persistent identifiers and clear explanations for their use. Storage and access \u00b6 Linked Data URIs resolve to descriptions access one object at a time Linked Data Fragments / Triple Pattern Fragments SPARQL endpoint RDF dumps in a TDR Informing the object holder \u00b6 When annotations are not stored by the provider (holder) of the annotated object, they may be informed about the annotations. Some providers may provide instructions for informing them. Correctness \u00b6 Annotations are RDF graphs and can include authorship information about the external body, but what if this doesn't match the metadata of the external body? The Web Annotation Model specifies that the external body's metadata is the canonical source. Access control \u00b6 Who can add, edit and delete annotations? How do you authenticate and authorise users? These decisions influence the integrity of your research data. Copyright and content policies \u00b6 What kind of content may be added in annotations? How will you monitor whether users adhere to this? What do you do in case of violations of copyright laws or content policies? Who decides what is allowed and who makes the final decision in case of a dispute over contents of annotations? The answers to these questions are perhaps more relevant to your research when you involve citizen science or crowdsourcing and when you cannot be sure that every contributor means well.","title":"Enriching Digital Objects: a Policy Framework"},{"location":"working-with-data/enriching-resources/policy-framework/#principles","text":"annotations are research data annotations enrich objects by adding or linking to information privacy of annotators ethical processing of annotation objects secure access to annotations preservation of annotations","title":"Principles"},{"location":"working-with-data/enriching-resources/policy-framework/#laws-and-regulations","text":"GDPR: see Data protection on the library website for some pointers Copyright","title":"Laws and regulations"},{"location":"working-with-data/enriching-resources/policy-framework/#policies","text":"Digitaal Erfgoed Referentiearchitectuur (DERA) defines four operational goals to implement its strategic goal, the third of which is 'Users can add new or external information when necessary.' This reference architecture is aimed at cultural heritage institutions, but this specific goal is clearly connected to our aim \u2013 to allow people to enrich digital objects.","title":"Policies"},{"location":"working-with-data/enriching-resources/policy-framework/#links-between-objects-and-enrichments","text":"Define object bounds and types of enrichments. Objects may consist of various components, like high-resolution master image(s), thumbnail(s) and transcriptions of the text in the object. Model enrichments as annotations directly or use an annotation to make discovering more complex external descriptions of the resource easier. The latter use of annotations may be useful when an enrichment is more than a single connection between two objects.","title":"Links between objects and enrichments"},{"location":"working-with-data/enriching-resources/policy-framework/#annotations-are-research-data","text":"All policies for research data also apply to annotations, and hence to enrichments as well. Enrichments should (thus) be FAIR. Use standards for annotations, like the Web Annotation Model .","title":"Annotations are research data"},{"location":"working-with-data/enriching-resources/policy-framework/#considerations","text":"","title":"Considerations"},{"location":"working-with-data/enriching-resources/policy-framework/#data-formats-for-annotations","text":"RDF CSV + CSV metadata JSON-LD Turtle RDFa Nanopublications other data formats Hypothes.is JSON brat stand-off format TEI VGG Image Annotator format (JSON or CSV)","title":"Data formats for annotations"},{"location":"working-with-data/enriching-resources/policy-framework/#bodies-of-annotations","text":"Annotations can have one or more bodies, or none (for specific motivations). If there are multiple bodies, they are usually related, but how they are related may vary. external, can be anything full resources fragments of resources embedded TextualBody HTML fragment plain text","title":"Bodies of annotations"},{"location":"working-with-data/enriching-resources/policy-framework/#example-tei-file-as-external-body","text":"When you transcribe text from manuscripts, you may want to use the TEI guidelines and markup. You can refer to (fragments of) external TEI files as the body of annotations.","title":"Example: TEI file as external body"},{"location":"working-with-data/enriching-resources/policy-framework/#example-html-file-as-external-body","text":"Many documents on the Web are available in HTML format. You can refer to (fragments of) HTML files as the body of annotations.","title":"Example: HTML file as external body"},{"location":"working-with-data/enriching-resources/policy-framework/#motivation-and-purpose-of-annotations","text":"In the Web Annotation Model, motivation and purpose are used to present a reason for the annotation, thereby also explaining the nature of the relationship between the target and the body of the annotation. Note The motivations and purposes defined by the Web Annotation Model are useful, but deliberately generic. They can be specialised, though any terms created for special purposes should get persistent identifiers and clear explanations for their use.","title":"Motivation and purpose of annotations"},{"location":"working-with-data/enriching-resources/policy-framework/#storage-and-access","text":"Linked Data URIs resolve to descriptions access one object at a time Linked Data Fragments / Triple Pattern Fragments SPARQL endpoint RDF dumps in a TDR","title":"Storage and access"},{"location":"working-with-data/enriching-resources/policy-framework/#informing-the-object-holder","text":"When annotations are not stored by the provider (holder) of the annotated object, they may be informed about the annotations. Some providers may provide instructions for informing them.","title":"Informing the object holder"},{"location":"working-with-data/enriching-resources/policy-framework/#correctness","text":"Annotations are RDF graphs and can include authorship information about the external body, but what if this doesn't match the metadata of the external body? The Web Annotation Model specifies that the external body's metadata is the canonical source.","title":"Correctness"},{"location":"working-with-data/enriching-resources/policy-framework/#access-control","text":"Who can add, edit and delete annotations? How do you authenticate and authorise users? These decisions influence the integrity of your research data.","title":"Access control"},{"location":"working-with-data/enriching-resources/policy-framework/#copyright-and-content-policies","text":"What kind of content may be added in annotations? How will you monitor whether users adhere to this? What do you do in case of violations of copyright laws or content policies? Who decides what is allowed and who makes the final decision in case of a dispute over contents of annotations? The answers to these questions are perhaps more relevant to your research when you involve citizen science or crowdsourcing and when you cannot be sure that every contributor means well.","title":"Copyright and content policies"},{"location":"working-with-data/enriching-resources/policy-images/","text":"Introduction \u00b6 This document should guide people 1 who want to enrich image-based materials such as photos, paintings and (scanned) texts with descriptive metadata, details, context, or what have you. The policies in this document are (somewhat) concrete recommendations for implementing the guiding principles in the Enrichment Policy Framework . Both the framework and the policies in this document are based on the Leiden University research data management policy framework . Policies \u00b6 Use IIIF and the Web Annotation Framework if possible \u00b6 The International Image Interoperability Framework (IIIF) is a community-based set of standards for publishing, presenting, describing and annotating images on the Web. IIIF relies heavily on the Web Annotation Framework , a W3C standard for annotating Web resources. Create abstract resources to annotate \u00b6 Use IIIF Canvases for pages/posters and annotate those instead of images. This is standard practice for IIIF-based resources. Don't copy if not necessary, always annotate the original \u00b6 If you want to enrich images provided online by trustworthy institutions you don't need to copy the images. It is okay to keep a backup copy, but connect enrichments to the originals to make them as useful as possible. Other people may have annotated the same images, but only by referring to each image using the same identifiers, can computers understand that all annotations are of the same image. Add provenance to annotations \u00b6 The Web Annotation Framework includes ways to attribute the creator(s) of each annotation, the time the annotation was created/generated, and the time(s) the annotation was modified. The tool(s) you use to annotate should help you keep track of your own work so that you can be credited for it, and held accountable. Naturally, if you only make the annotations of others available, you should include the identities of the original creators. Record provenance and licenses of source images \u00b6 Explain how the set of images you selected for enrichment was created. This helps people assess how complete your set is and how representative it is among all similar images. If you have copies of images, keep the licence conditions and creator information (and all other relevant provenance) close and preferably linked to the images. You need to cite and deposit your data and this will help determine if and how images can be shared. Store enrichments in a trustworthy data repository \u00b6 If using IIIF and e.g. Mirador to create and save annotations, make sure the annotations are stored on a server that securely stores them and that creates backups. The server should store the provenance of each annotation too and if necessary, all versions of annotations. Identify, identify, identify \u00b6 Make sure everything has identifiers, preferably persistent identifiers (PIDs). You should use PIDs for images you annotate, and the server that stores your annotations should create PIDs for each (version of an) annotation. This allows users to connect the right versions of annotations to the right versions of images and recreate the context of the annotation at the time of its creation. Note The Web Annotation Model has another option to specify which representation of a resource was annotated: Resource State . Although we say people, the main audience is researchers. \u21a9","title":"Policies for enriching images"},{"location":"working-with-data/enriching-resources/policy-images/#introduction","text":"This document should guide people 1 who want to enrich image-based materials such as photos, paintings and (scanned) texts with descriptive metadata, details, context, or what have you. The policies in this document are (somewhat) concrete recommendations for implementing the guiding principles in the Enrichment Policy Framework . Both the framework and the policies in this document are based on the Leiden University research data management policy framework .","title":"Introduction"},{"location":"working-with-data/enriching-resources/policy-images/#policies","text":"","title":"Policies"},{"location":"working-with-data/enriching-resources/policy-images/#use-iiif-and-the-web-annotation-framework-if-possible","text":"The International Image Interoperability Framework (IIIF) is a community-based set of standards for publishing, presenting, describing and annotating images on the Web. IIIF relies heavily on the Web Annotation Framework , a W3C standard for annotating Web resources.","title":"Use IIIF and the Web Annotation Framework if possible"},{"location":"working-with-data/enriching-resources/policy-images/#create-abstract-resources-to-annotate","text":"Use IIIF Canvases for pages/posters and annotate those instead of images. This is standard practice for IIIF-based resources.","title":"Create abstract resources to annotate"},{"location":"working-with-data/enriching-resources/policy-images/#dont-copy-if-not-necessary-always-annotate-the-original","text":"If you want to enrich images provided online by trustworthy institutions you don't need to copy the images. It is okay to keep a backup copy, but connect enrichments to the originals to make them as useful as possible. Other people may have annotated the same images, but only by referring to each image using the same identifiers, can computers understand that all annotations are of the same image.","title":"Don't copy if not necessary, always annotate the original"},{"location":"working-with-data/enriching-resources/policy-images/#add-provenance-to-annotations","text":"The Web Annotation Framework includes ways to attribute the creator(s) of each annotation, the time the annotation was created/generated, and the time(s) the annotation was modified. The tool(s) you use to annotate should help you keep track of your own work so that you can be credited for it, and held accountable. Naturally, if you only make the annotations of others available, you should include the identities of the original creators.","title":"Add provenance to annotations"},{"location":"working-with-data/enriching-resources/policy-images/#record-provenance-and-licenses-of-source-images","text":"Explain how the set of images you selected for enrichment was created. This helps people assess how complete your set is and how representative it is among all similar images. If you have copies of images, keep the licence conditions and creator information (and all other relevant provenance) close and preferably linked to the images. You need to cite and deposit your data and this will help determine if and how images can be shared.","title":"Record provenance and licenses of source images"},{"location":"working-with-data/enriching-resources/policy-images/#store-enrichments-in-a-trustworthy-data-repository","text":"If using IIIF and e.g. Mirador to create and save annotations, make sure the annotations are stored on a server that securely stores them and that creates backups. The server should store the provenance of each annotation too and if necessary, all versions of annotations.","title":"Store enrichments in a trustworthy data repository"},{"location":"working-with-data/enriching-resources/policy-images/#identify-identify-identify","text":"Make sure everything has identifiers, preferably persistent identifiers (PIDs). You should use PIDs for images you annotate, and the server that stores your annotations should create PIDs for each (version of an) annotation. This allows users to connect the right versions of annotations to the right versions of images and recreate the context of the annotation at the time of its creation. Note The Web Annotation Model has another option to specify which representation of a resource was annotated: Resource State . Although we say people, the main audience is researchers. \u21a9","title":"Identify, identify, identify"},{"location":"working-with-data/enriching-resources/policy-text/","text":"Introduction \u00b6 See also \u00b6 https://github.com/CLARIAH/scholarly-web-annotation-client","title":"Policies for enriching texts"},{"location":"working-with-data/enriching-resources/policy-text/#introduction","text":"","title":"Introduction"},{"location":"working-with-data/enriching-resources/policy-text/#see-also","text":"https://github.com/CLARIAH/scholarly-web-annotation-client","title":"See also"},{"location":"working-with-data/processing-data/","text":"","title":"Processing data"},{"location":"working-with-data/processing-data/htr/","text":"Tools for recognising handwritten text in images, or HTR, are listed on this page. Transkribus \u00b6 Free to use on a small scale; you need to pay to run HTR on larger numbers of pages. Transkribus is run by the European cooperative society READ-COOP . Member institutions and persons have more credits for using Transkribus HTR. Note Transkribus needs to store your images on their servers for analysis and HTR to work. Monk \u00b6 Monk was developed at the RUG . It is not possible to create an account without permission of the creators. eScriptorium \u00b6 eScriptorium is an open-source platform for HTR, developed as part of the PSL Scripta project. Permission from the project partners is needed to use the platform, or you need to set up your own service.","title":"Handwritten-text recognition (HTR)"},{"location":"working-with-data/processing-data/htr/#transkribus","text":"Free to use on a small scale; you need to pay to run HTR on larger numbers of pages. Transkribus is run by the European cooperative society READ-COOP . Member institutions and persons have more credits for using Transkribus HTR. Note Transkribus needs to store your images on their servers for analysis and HTR to work.","title":"Transkribus"},{"location":"working-with-data/processing-data/htr/#monk","text":"Monk was developed at the RUG . It is not possible to create an account without permission of the creators.","title":"Monk"},{"location":"working-with-data/processing-data/htr/#escriptorium","text":"eScriptorium is an open-source platform for HTR, developed as part of the PSL Scripta project. Permission from the project partners is needed to use the platform, or you need to set up your own service.","title":"eScriptorium"},{"location":"working-with-data/processing-data/ocr/","text":"Recognise print text in images with any of these tools. ABBYY FineReader \u00b6 ABBYY FineReader is considered very good for OCR in many languages. However, it is not cheap. Adobe Acrobat \u00b6 Adobe Acrobat has OCR capabilities for PDFs. However, not all languages are supported (e.g. Arabic). Tesseract \u00b6 Tesseract is open source and free to use. It has support for many languages, can be (re)trained for other languages and achieves good results. It requires a little knowledge of the command line and supports only a limited number of image formats for inputs. OCRmyPDF \u00b6 For PDFs without a text layer, OCRmyPDF is a very useful toolkit. It is a command-line tool that uses Tesseract under the hood, as well as various preprocessing tools to straighten (deskew) the text lines and removing noise \u2013 if you want it to. Kraken / Ocropy \u00b6 Kraken and Ocropy are related OCR applications, as they build on one another. They are both open source and free to use. Kraken is relatively easy to train. Instead of full pages, Kraken recognises text in single lines. Calamari \u00b6 Calamari is also open source and free to use.","title":"Optical character recognition (OCR)"},{"location":"working-with-data/processing-data/ocr/#abbyy-finereader","text":"ABBYY FineReader is considered very good for OCR in many languages. However, it is not cheap.","title":"ABBYY FineReader"},{"location":"working-with-data/processing-data/ocr/#adobe-acrobat","text":"Adobe Acrobat has OCR capabilities for PDFs. However, not all languages are supported (e.g. Arabic).","title":"Adobe Acrobat"},{"location":"working-with-data/processing-data/ocr/#tesseract","text":"Tesseract is open source and free to use. It has support for many languages, can be (re)trained for other languages and achieves good results. It requires a little knowledge of the command line and supports only a limited number of image formats for inputs.","title":"Tesseract"},{"location":"working-with-data/processing-data/ocr/#ocrmypdf","text":"For PDFs without a text layer, OCRmyPDF is a very useful toolkit. It is a command-line tool that uses Tesseract under the hood, as well as various preprocessing tools to straighten (deskew) the text lines and removing noise \u2013 if you want it to.","title":"OCRmyPDF"},{"location":"working-with-data/processing-data/ocr/#kraken-ocropy","text":"Kraken and Ocropy are related OCR applications, as they build on one another. They are both open source and free to use. Kraken is relatively easy to train. Instead of full pages, Kraken recognises text in single lines.","title":"Kraken / Ocropy"},{"location":"working-with-data/processing-data/ocr/#calamari","text":"Calamari is also open source and free to use.","title":"Calamari"},{"location":"working-with-data/publishing-data/","text":"Pre-publishing checks \u00b6 rights sensitive data referring back to your DMP Archiving \u00b6 Create a self-contained dataset and store it in an archive. 'Live data' \u00b6 If possible, it would be great to have your data directly accessible online, in a way that does not require others to download the complete set. You could publish files or provide an API to your data.","title":"Publishing your data"},{"location":"working-with-data/publishing-data/#pre-publishing-checks","text":"rights sensitive data referring back to your DMP","title":"Pre-publishing checks"},{"location":"working-with-data/publishing-data/#archiving","text":"Create a self-contained dataset and store it in an archive.","title":"Archiving"},{"location":"working-with-data/publishing-data/#live-data","text":"If possible, it would be great to have your data directly accessible online, in a way that does not require others to download the complete set. You could publish files or provide an API to your data.","title":"'Live data'"},{"location":"working-with-data/publishing-data/api/","text":"","title":"Application programming interfaces (APIs)"},{"location":"working-with-data/publishing-data/archiving/","text":"","title":"Archiving research data"},{"location":"working-with-data/publishing-data/csv-on-the-web/","text":"","title":"CSV on the Web"},{"location":"working-with-data/publishing-data/linked-data-fragments/","text":"","title":"Linked Data Fragments"},{"location":"working-with-data/publishing-data/linked-data/","text":"","title":"Linked Data"},{"location":"working-with-data/publishing-data/nanopublications/","text":"Nanopublications are small units of publication, \"implemented in\" RDF . Each nanopub contains assertions, provenance and publication information. Assertions are the core contributions of the publication. Provenance links the contributions to methods, previous data and publications. Publication information is the metadata of the nanopub: who are responsible for it, when was it published? Although nanopubs can be distributed as files, there is an elaborate system of applications to help create nanopubs and server applications to publish them.","title":"Nanopublications"},{"location":"working-with-data/reusing-data/","text":"","title":"Reusing data"},{"location":"working-with-data/reusing-data/web-scraping/","text":"","title":"Web scraping"}]}